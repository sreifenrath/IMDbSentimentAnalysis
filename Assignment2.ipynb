{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the data from tar.gz file\n",
    "import tarfile\n",
    "tf = tarfile.open(\"aclImdb_v1.tar.gz\")\n",
    "tf.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting/organizing the data\n",
    "        \n",
    "pos_reviews_train = []\n",
    "neg_reviews_train = []\n",
    "pos_reviews_test = []\n",
    "neg_reviews_test = []\n",
    "\n",
    "directory = \"aclImdb/train/pos/\"\n",
    "for filename in os.listdir(directory) :\n",
    "    f = os.path.join(directory, filename)\n",
    "    file = open(f, \"r\", encoding='UTF8')\n",
    "    text = file.read()\n",
    "    pos_reviews_train.append(text)\n",
    "\n",
    "directory = \"aclImdb/test/pos/\"\n",
    "for filename in os.listdir(directory) :\n",
    "    f = os.path.join(directory, filename)\n",
    "    file = open(f, \"r\", encoding='UTF8')\n",
    "    text = file.read()\n",
    "    pos_reviews_test.append(text)\n",
    "\n",
    "directory = \"aclImdb/train/neg/\"\n",
    "for filename in os.listdir(directory) :\n",
    "    f = os.path.join(directory, filename)\n",
    "    file = open(f, \"r\", encoding='UTF8')\n",
    "    text = file.read()\n",
    "    neg_reviews_train.append(text)\n",
    "\n",
    "directory = \"aclImdb/test/neg/\"\n",
    "for filename in os.listdir(directory) :\n",
    "    f = os.path.join(directory, filename)\n",
    "    file = open(f, \"r\", encoding='UTF8')\n",
    "    text = file.read()\n",
    "    neg_reviews_test.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dfs for train and test data\n",
    "train_df = pd.DataFrame(pos_reviews_train + neg_reviews_train, columns = [\"text\"])\n",
    "train_df[\"sentiment\"] = [1] * len(pos_reviews_train) + [0] * len(neg_reviews_train)\n",
    "test_df = pd.DataFrame(pos_reviews_test + neg_reviews_test, columns = [\"text\"])\n",
    "test_df[\"sentiment\"] = [1] * len(pos_reviews_test) + [0] * len(neg_reviews_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bag of words vectorizer with only unigrams\n",
    "v = CountVectorizer()\n",
    "X_train_uni = v.fit_transform(train_df[\"text\"])\n",
    "y_train_uni = train_df[\"sentiment\"]\n",
    "X_test_uni = v.transform(test_df[\"text\"])\n",
    "y_test_uni = test_df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83     12500\n",
      "           1       0.86      0.75      0.80     12500\n",
      "\n",
      "    accuracy                           0.81     25000\n",
      "   macro avg       0.82      0.81      0.81     25000\n",
      "weighted avg       0.82      0.81      0.81     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a model using Naive Bayes to test unigram bag of words\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_uni, y_train_uni)\n",
    "nb.score(X_test_uni, y_test_uni)\n",
    "y_pred_uni = nb.predict(X_test_uni)\n",
    "print(classification_report(y_test_uni, y_pred_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizer and bigrams\n",
    "tfidf = TfidfVectorizer(ngram_range=(2,2))\n",
    "X_train_bi = tfidf.fit_transform(train_df[\"text\"])\n",
    "y_train_bi = train_df[\"sentiment\"]\n",
    "X_test_bi = tfidf.transform(test_df[\"text\"])\n",
    "y_test_bi = test_df[\"sentiment\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88     12500\n",
      "           1       0.91      0.84      0.87     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a model using Naive Bayes to test bigram bag of words\n",
    "nb.fit(X_train_bi, y_train_bi)\n",
    "nb.score(X_test_bi, y_test_bi)\n",
    "y_pred_bi = nb.predict(X_test_bi)\n",
    "print(classification_report(y_test_bi, y_pred_bi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word tokenizer for LSTM model\n",
    "word_tokenizer = Tokenizer()\n",
    "X_train_LSTM = train_df[\"text\"]\n",
    "y_train_LSTM = train_df[\"sentiment\"]\n",
    "X_test_LSTM = test_df[\"text\"]\n",
    "y_test_LSTM = test_df[\"sentiment\"]\n",
    "word_tokenizer.fit_on_texts(X_train_LSTM)\n",
    "X_train_LSTM = word_tokenizer.texts_to_sequences(X_train_LSTM)\n",
    "X_test_LSTM = word_tokenizer.texts_to_sequences(X_test_LSTM)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "# Padding the reviews to make them of same length\n",
    "maxsize = 100\n",
    "X_train_LSTM = sequence.pad_sequences(X_train_LSTM, padding='post', maxlen=maxsize)\n",
    "X_test_LSTM = sequence.pad_sequences(X_test_LSTM, padding='post', maxlen=maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sequential model using LSTM\n",
    "embedding_size = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=maxsize))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 86s 106ms/step - loss: 0.4270 - accuracy: 0.8001 - val_loss: 0.3839 - val_accuracy: 0.8372\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 81s 103ms/step - loss: 0.2227 - accuracy: 0.9176 - val_loss: 0.3702 - val_accuracy: 0.8398\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 85s 109ms/step - loss: 0.1370 - accuracy: 0.9527 - val_loss: 0.4302 - val_accuracy: 0.8257\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.4302 - accuracy: 0.8257\n",
      "Accuracy: 82.572001\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_LSTM, y_train_LSTM, epochs=3, verbose=1, validation_data=(X_test_LSTM, y_test_LSTM))\n",
    "loss, accuracy = model.evaluate(X_test_LSTM, y_test_LSTM, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
